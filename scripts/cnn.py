# -*- coding: utf-8 -*-
"""CNN KERAS.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ktL7EB7WLPtgtJ-yXV9W5KfxqndbPMCj
"""

from tensorflow.keras.optimizers import Adam
from tensorflow.keras.models import Sequential
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Input
import tensorflow as tf
import numpy as np

# Constants
image_w, image_h = 210, 160
batch_size = 32

# path to the folder where the frames are located
data_dir = "/content/drive/MyDrive/frames"

# Load the images as a dataset and resize them
train_data_generator = ImageDataGenerator(
    rescale=1./255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    validation_split=0.2)

train_generator = train_data_generator.flow_from_directory(
    data_dir,
    target_size=(image_w, image_h),
    batch_size=batch_size,
    class_mode='binary',
    subset='training') # set as training data

validation_generator = train_data_generator.flow_from_directory(
    data_dir, # same directory as training data
    target_size=(image_w, image_h),
    batch_size=batch_size,
    class_mode='binary',
    subset='validation') # set as validation data

# Build Model
model = Sequential()
model.add(Conv2D(32, kernel_size=(5, 5), padding="same", input_shape=(image_w, image_h, 3)))
model.add(Activation("relu"))
model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))
model.add(Conv2D(64, kernel_size=(5, 5), padding="same"))
model.add(Activation("relu"))
model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))
model.add(Conv2D(128, kernel_size=(5, 5), padding="same"))
model.add(Activation("relu"))
model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))

model.add(Flatten())
model.add(Dense(128, activation= "relu"))
model.add(Dense(1, activation= "sigmoid"))

# Optimizer
optimizer = Adam(learning_rate=0.001)

# Compile Model
model.compile(optimizer=optimizer, loss="binary_crossentropy", metrics=['accuracy'])

model.fit(
    train_generator,
    steps_per_epoch = 200,
    epochs = 20,
    validation_data = validation_generator, 
    validation_steps = 100)

model.summary()

# Saving Model
# model.save("cnn_model.h5")